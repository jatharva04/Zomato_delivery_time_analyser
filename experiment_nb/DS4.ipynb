{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LJgEvxUjhmH4",
        "outputId": "9cc51270-9fbe-457a-a0c0-82f41e28bc69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting dvc[gdrive]\n",
            "  Downloading dvc-3.63.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from dvc[gdrive]) (25.3.0)\n",
            "Collecting celery (from dvc[gdrive])\n",
            "  Downloading celery-5.5.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting colorama>=0.3.9 (from dvc[gdrive])\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting configobj>=5.0.9 (from dvc[gdrive])\n",
            "  Downloading configobj-5.0.9-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: distro>=1.3 in /usr/local/lib/python3.12/dist-packages (from dvc[gdrive]) (1.9.0)\n",
            "Collecting dpath<3,>=2.1.0 (from dvc[gdrive])\n",
            "  Downloading dpath-2.2.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting dulwich (from dvc[gdrive])\n",
            "  Downloading dulwich-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting dvc-data<3.17,>=3.16.2 (from dvc[gdrive])\n",
            "  Downloading dvc_data-3.16.12-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting dvc-http>=2.29.0 (from dvc[gdrive])\n",
            "  Downloading dvc_http-2.32.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting dvc-objects (from dvc[gdrive])\n",
            "  Downloading dvc_objects-5.1.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting dvc-render<2,>=1.0.1 (from dvc[gdrive])\n",
            "  Downloading dvc_render-1.0.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting dvc-studio-client<1,>=0.21 (from dvc[gdrive])\n",
            "  Downloading dvc_studio_client-0.22.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting dvc-task<1,>=0.3.0 (from dvc[gdrive])\n",
            "  Downloading dvc_task-0.40.2-py3-none-any.whl.metadata (10.0 kB)\n",
            "Collecting flatten_dict<1,>=0.4.1 (from dvc[gdrive])\n",
            "  Downloading flatten_dict-0.4.2-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting flufl.lock<9,>=8.1.0 (from dvc[gdrive])\n",
            "  Downloading flufl_lock-8.2.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: fsspec>=2024.2.0 in /usr/local/lib/python3.12/dist-packages (from dvc[gdrive]) (2025.3.0)\n",
            "Collecting funcy>=1.14 (from dvc[gdrive])\n",
            "  Downloading funcy-2.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting grandalf<1,>=0.7 (from dvc[gdrive])\n",
            "  Downloading grandalf-0.8-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting gto<2,>=1.6.0 (from dvc[gdrive])\n",
            "  Downloading gto-1.8.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting hydra-core>=1.1 (from dvc[gdrive])\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting iterative-telemetry>=0.0.7 (from dvc[gdrive])\n",
            "  Downloading iterative_telemetry-0.0.10-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting kombu (from dvc[gdrive])\n",
            "  Downloading kombu-5.5.4-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.12/dist-packages (from dvc[gdrive]) (3.5)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.12/dist-packages (from dvc[gdrive]) (2.3.0)\n",
            "Requirement already satisfied: packaging>=19 in /usr/local/lib/python3.12/dist-packages (from dvc[gdrive]) (25.0)\n",
            "Collecting pathspec>=0.10.3 (from dvc[gdrive])\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.1.1 in /usr/local/lib/python3.12/dist-packages (from dvc[gdrive]) (4.4.0)\n",
            "Requirement already satisfied: psutil>=5.8 in /usr/local/lib/python3.12/dist-packages (from dvc[gdrive]) (5.9.5)\n",
            "Requirement already satisfied: pydot>=1.2.4 in /usr/local/lib/python3.12/dist-packages (from dvc[gdrive]) (3.0.4)\n",
            "Collecting pygtrie>=2.3.2 (from dvc[gdrive])\n",
            "  Downloading pygtrie-2.5.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: pyparsing>=2.4.7 in /usr/local/lib/python3.12/dist-packages (from dvc[gdrive]) (3.2.4)\n",
            "Requirement already satisfied: requests>=2.22 in /usr/local/lib/python3.12/dist-packages (from dvc[gdrive]) (2.32.4)\n",
            "Requirement already satisfied: rich>=12 in /usr/local/lib/python3.12/dist-packages (from dvc[gdrive]) (13.9.4)\n",
            "Collecting ruamel.yaml>=0.17.11 (from dvc[gdrive])\n",
            "  Downloading ruamel.yaml-0.18.15-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting scmrepo<4,>=3.5.2 (from dvc[gdrive])\n",
            "  Downloading scmrepo-3.5.2-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting shortuuid>=0.5 (from dvc[gdrive])\n",
            "  Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting shtab<2,>=1.3.4 (from dvc[gdrive])\n",
            "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.7 in /usr/local/lib/python3.12/dist-packages (from dvc[gdrive]) (0.9.0)\n",
            "Requirement already satisfied: tomlkit>=0.11.1 in /usr/local/lib/python3.12/dist-packages (from dvc[gdrive]) (0.13.3)\n",
            "Requirement already satisfied: tqdm<5,>=4.63.1 in /usr/local/lib/python3.12/dist-packages (from dvc[gdrive]) (4.67.1)\n",
            "Collecting voluptuous>=0.11.7 (from dvc[gdrive])\n",
            "  Downloading voluptuous-0.15.2-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting zc.lockfile>=1.2.1 (from dvc[gdrive])\n",
            "  Downloading zc_lockfile-4.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting dvc-gdrive<4,>=3 (from dvc[gdrive])\n",
            "  Downloading dvc_gdrive-3.0.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting dictdiffer>=0.8.1 (from dvc-data<3.17,>=3.16.2->dvc[gdrive])\n",
            "  Downloading dictdiffer-0.9.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting diskcache>=5.2.1 (from dvc-data<3.17,>=3.16.2->dvc[gdrive])\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting sqltrie<1,>=0.11.0 (from dvc-data<3.17,>=3.16.2->dvc[gdrive])\n",
            "  Downloading sqltrie-0.11.2-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: orjson<4,>=3 in /usr/local/lib/python3.12/dist-packages (from dvc-data<3.17,>=3.16.2->dvc[gdrive]) (3.11.3)\n",
            "Requirement already satisfied: pydrive2>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from pydrive2[fsspec]>=1.19.0->dvc-gdrive<4,>=3->dvc[gdrive]) (1.21.3)\n",
            "Collecting aiohttp-retry>=2.5.0 (from dvc-http>=2.29.0->dvc[gdrive])\n",
            "  Downloading aiohttp_retry-2.9.1-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting billiard<5.0,>=4.2.1 (from celery->dvc[gdrive])\n",
            "  Downloading billiard-4.2.2-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting vine<6.0,>=5.1.0 (from celery->dvc[gdrive])\n",
            "  Downloading vine-5.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: click<9.0,>=8.1.2 in /usr/local/lib/python3.12/dist-packages (from celery->dvc[gdrive]) (8.2.1)\n",
            "Collecting click-didyoumean>=0.3.0 (from celery->dvc[gdrive])\n",
            "  Downloading click_didyoumean-0.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting click-repl>=0.2.0 (from celery->dvc[gdrive])\n",
            "  Downloading click_repl-0.3.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting click-plugins>=1.1.1 (from celery->dvc[gdrive])\n",
            "  Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from celery->dvc[gdrive]) (2.9.0.post0)\n",
            "Requirement already satisfied: six<2.0,>=1.12 in /usr/local/lib/python3.12/dist-packages (from flatten_dict<1,>=0.4.1->dvc[gdrive]) (1.17.0)\n",
            "Requirement already satisfied: atpublic in /usr/local/lib/python3.12/dist-packages (from flufl.lock<9,>=8.1.0->dvc[gdrive]) (5.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from gto<2,>=1.6.0->dvc[gdrive]) (0.4)\n",
            "Requirement already satisfied: pydantic!=2.0.0,<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from gto<2,>=1.6.0->dvc[gdrive]) (2.11.9)\n",
            "Collecting semver>=2.13.0 (from gto<2,>=1.6.0->dvc[gdrive])\n",
            "  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: typer>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from gto<2,>=1.6.0->dvc[gdrive]) (0.17.4)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core>=1.1->dvc[gdrive]) (4.9.3)\n",
            "Collecting appdirs (from iterative-telemetry>=0.0.7->dvc[gdrive])\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from iterative-telemetry>=0.0.7->dvc[gdrive]) (3.19.1)\n",
            "Collecting amqp<6.0.0,>=5.1.1 (from kombu->dvc[gdrive])\n",
            "  Downloading amqp-5.3.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: tzdata>=2025.2 in /usr/local/lib/python3.12/dist-packages (from kombu->dvc[gdrive]) (2025.2)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from omegaconf->dvc[gdrive]) (6.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.22->dvc[gdrive]) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.22->dvc[gdrive]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.22->dvc[gdrive]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.22->dvc[gdrive]) (2025.8.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12->dvc[gdrive]) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12->dvc[gdrive]) (2.19.2)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.11->dvc[gdrive])\n",
            "  Downloading ruamel.yaml.clib-0.2.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: gitpython>3 in /usr/local/lib/python3.12/dist-packages (from scmrepo<4,>=3.5.2->dvc[gdrive]) (3.1.45)\n",
            "Requirement already satisfied: pygit2>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from scmrepo<4,>=3.5.2->dvc[gdrive]) (1.18.2)\n",
            "Collecting asyncssh<3,>=2.13.1 (from scmrepo<4,>=3.5.2->dvc[gdrive])\n",
            "  Downloading asyncssh-2.21.0-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from zc.lockfile>=1.2.1->dvc[gdrive]) (75.2.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from aiohttp-retry>=2.5.0->dvc-http>=2.29.0->dvc[gdrive]) (3.12.15)\n",
            "Requirement already satisfied: cryptography>=39.0 in /usr/local/lib/python3.12/dist-packages (from asyncssh<3,>=2.13.1->scmrepo<4,>=3.5.2->dvc[gdrive]) (43.0.3)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from asyncssh<3,>=2.13.1->scmrepo<4,>=3.5.2->dvc[gdrive]) (4.15.0)\n",
            "Requirement already satisfied: prompt-toolkit>=3.0.36 in /usr/local/lib/python3.12/dist-packages (from click-repl>=0.2.0->celery->dvc[gdrive]) (3.0.52)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython>3->scmrepo<4,>=3.5.2->dvc[gdrive]) (4.0.12)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12->dvc[gdrive]) (0.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.0,<3,>=1.9.0->gto<2,>=1.6.0->dvc[gdrive]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.0,<3,>=1.9.0->gto<2,>=1.6.0->dvc[gdrive]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.0,<3,>=1.9.0->gto<2,>=1.6.0->dvc[gdrive]) (0.4.1)\n",
            "Requirement already satisfied: google-api-python-client>=1.12.5 in /usr/local/lib/python3.12/dist-packages (from pydrive2>=1.19.0->pydrive2[fsspec]>=1.19.0->dvc-gdrive<4,>=3->dvc[gdrive]) (2.182.0)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from pydrive2>=1.19.0->pydrive2[fsspec]>=1.19.0->dvc-gdrive<4,>=3->dvc[gdrive]) (4.1.3)\n",
            "Requirement already satisfied: pyOpenSSL<=24.2.1,>=19.1.0 in /usr/local/lib/python3.12/dist-packages (from pydrive2>=1.19.0->pydrive2[fsspec]>=1.19.0->dvc-gdrive<4,>=3->dvc[gdrive]) (24.2.1)\n",
            "Requirement already satisfied: cffi>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from pygit2>=1.14.0->scmrepo<4,>=3.5.2->dvc[gdrive]) (2.0.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.4.1->gto<2,>=1.6.0->dvc[gdrive]) (1.5.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->aiohttp-retry>=2.5.0->dvc-http>=2.29.0->dvc[gdrive]) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->aiohttp-retry>=2.5.0->dvc-http>=2.29.0->dvc[gdrive]) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->aiohttp-retry>=2.5.0->dvc-http>=2.29.0->dvc[gdrive]) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->aiohttp-retry>=2.5.0->dvc-http>=2.29.0->dvc[gdrive]) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->aiohttp-retry>=2.5.0->dvc-http>=2.29.0->dvc[gdrive]) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->aiohttp-retry>=2.5.0->dvc-http>=2.29.0->dvc[gdrive]) (1.20.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.17.0->pygit2>=1.14.0->scmrepo<4,>=3.5.2->dvc[gdrive]) (2.23)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython>3->scmrepo<4,>=3.5.2->dvc[gdrive]) (5.0.2)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.12.5->pydrive2>=1.19.0->pydrive2[fsspec]>=1.19.0->dvc-gdrive<4,>=3->dvc[gdrive]) (0.31.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.12.5->pydrive2>=1.19.0->pydrive2[fsspec]>=1.19.0->dvc-gdrive<4,>=3->dvc[gdrive]) (2.38.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.12.5->pydrive2>=1.19.0->pydrive2[fsspec]>=1.19.0->dvc-gdrive<4,>=3->dvc[gdrive]) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.12.5->pydrive2>=1.19.0->pydrive2[fsspec]>=1.19.0->dvc-gdrive<4,>=3->dvc[gdrive]) (2.25.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.12.5->pydrive2>=1.19.0->pydrive2[fsspec]>=1.19.0->dvc-gdrive<4,>=3->dvc[gdrive]) (4.2.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from oauth2client>=4.0.0->pydrive2>=1.19.0->pydrive2[fsspec]>=1.19.0->dvc-gdrive<4,>=3->dvc[gdrive]) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.12/dist-packages (from oauth2client>=4.0.0->pydrive2>=1.19.0->pydrive2[fsspec]>=1.19.0->dvc-gdrive<4,>=3->dvc[gdrive]) (0.4.2)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from oauth2client>=4.0.0->pydrive2>=1.19.0->pydrive2[fsspec]>=1.19.0->dvc-gdrive<4,>=3->dvc[gdrive]) (4.9.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit>=3.0.36->click-repl>=0.2.0->celery->dvc[gdrive]) (0.2.13)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.5->pydrive2>=1.19.0->pydrive2[fsspec]>=1.19.0->dvc-gdrive<4,>=3->dvc[gdrive]) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.5->pydrive2>=1.19.0->pydrive2[fsspec]>=1.19.0->dvc-gdrive<4,>=3->dvc[gdrive]) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.5->pydrive2>=1.19.0->pydrive2[fsspec]>=1.19.0->dvc-gdrive<4,>=3->dvc[gdrive]) (1.26.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=1.12.5->pydrive2>=1.19.0->pydrive2[fsspec]>=1.19.0->dvc-gdrive<4,>=3->dvc[gdrive]) (5.5.2)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading configobj-5.0.9-py2.py3-none-any.whl (35 kB)\n",
            "Downloading dpath-2.2.0-py3-none-any.whl (17 kB)\n",
            "Downloading dvc_data-3.16.12-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dvc_gdrive-3.0.1-py3-none-any.whl (11 kB)\n",
            "Downloading dvc_http-2.32.0-py3-none-any.whl (12 kB)\n",
            "Downloading dvc_objects-5.1.1-py3-none-any.whl (33 kB)\n",
            "Downloading dvc_render-1.0.2-py3-none-any.whl (22 kB)\n",
            "Downloading dvc_studio_client-0.22.0-py3-none-any.whl (16 kB)\n",
            "Downloading dvc_task-0.40.2-py3-none-any.whl (21 kB)\n",
            "Downloading celery-5.5.3-py3-none-any.whl (438 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.8/438.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flatten_dict-0.4.2-py2.py3-none-any.whl (9.7 kB)\n",
            "Downloading flufl_lock-8.2.0-py3-none-any.whl (11 kB)\n",
            "Downloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
            "Downloading grandalf-0.8-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gto-1.8.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading iterative_telemetry-0.0.10-py3-none-any.whl (10 kB)\n",
            "Downloading kombu-5.5.4-py3-none-any.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading vine-5.1.0-py3-none-any.whl (9.6 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading pygtrie-2.5.0-py3-none-any.whl (25 kB)\n",
            "Downloading ruamel.yaml-0.18.15-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scmrepo-3.5.2-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.9/73.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dulwich-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
            "Downloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
            "Downloading voluptuous-0.15.2-py3-none-any.whl (31 kB)\n",
            "Downloading zc_lockfile-4.0-py3-none-any.whl (9.1 kB)\n",
            "Downloading dvc-3.63.0-py3-none-any.whl (466 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m466.2/466.2 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp_retry-2.9.1-py3-none-any.whl (10.0 kB)\n",
            "Downloading amqp-5.3.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asyncssh-2.21.0-py3-none-any.whl (374 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.9/374.9 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading billiard-4.2.2-py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click_didyoumean-0.3.1-py3-none-any.whl (3.6 kB)\n",
            "Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl (11 kB)\n",
            "Downloading click_repl-0.3.0-py3-none-any.whl (10 kB)\n",
            "Downloading dictdiffer-0.9.0-py2.py3-none-any.whl (16 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading ruamel.yaml.clib-0.2.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (753 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m753.1/753.1 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
            "Downloading sqltrie-0.11.2-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: pygtrie, funcy, dictdiffer, appdirs, zc.lockfile, voluptuous, vine, sqltrie, shtab, shortuuid, semver, ruamel.yaml.clib, pathspec, grandalf, flufl.lock, flatten_dict, dvc-render, dvc-objects, dulwich, dpath, diskcache, configobj, colorama, click-plugins, click-didyoumean, billiard, ruamel.yaml, iterative-telemetry, hydra-core, dvc-studio-client, dvc-data, click-repl, amqp, kombu, asyncssh, aiohttp-retry, scmrepo, dvc-http, celery, gto, dvc-task, dvc, dvc-gdrive\n",
            "Successfully installed aiohttp-retry-2.9.1 amqp-5.3.1 appdirs-1.4.4 asyncssh-2.21.0 billiard-4.2.2 celery-5.5.3 click-didyoumean-0.3.1 click-plugins-1.1.1.2 click-repl-0.3.0 colorama-0.4.6 configobj-5.0.9 dictdiffer-0.9.0 diskcache-5.6.3 dpath-2.2.0 dulwich-0.24.1 dvc-3.63.0 dvc-data-3.16.12 dvc-gdrive-3.0.1 dvc-http-2.32.0 dvc-objects-5.1.1 dvc-render-1.0.2 dvc-studio-client-0.22.0 dvc-task-0.40.2 flatten_dict-0.4.2 flufl.lock-8.2.0 funcy-2.0 grandalf-0.8 gto-1.8.0 hydra-core-1.3.2 iterative-telemetry-0.0.10 kombu-5.5.4 pathspec-0.12.1 pygtrie-2.5.0 ruamel.yaml-0.18.15 ruamel.yaml.clib-0.2.14 scmrepo-3.5.2 semver-3.0.4 shortuuid-1.0.13 shtab-1.7.2 sqltrie-0.11.2 vine-5.1.0 voluptuous-0.15.2 zc.lockfile-4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install \"dvc[gdrive]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz4kVN6Zig6p",
        "outputId": "358f036f-7abc-4c1f-b0a5-f5b043ab3155"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset loaded successfully!\n",
            "Shape of the dataset: (45094, 21)\n",
            "Index(['ID', 'Delivery_person_ID', 'Delivery_person_Age',\n",
            "       'Delivery_person_Ratings', 'Restaurant_latitude',\n",
            "       'Restaurant_longitude', 'Delivery_location_latitude',\n",
            "       'Delivery_location_longitude', 'Order_Date', 'Time_Orderd',\n",
            "       'Time_Order_picked', 'Weather_conditions', 'Road_traffic_density',\n",
            "       'Vehicle_condition', 'Type_of_order', 'Type_of_vehicle',\n",
            "       'multiple_deliveries', 'Festival', 'City', 'Time_taken (min)',\n",
            "       'distance (km)'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import dvc.api\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "repo_url = 'https://github.com/AshwinVK23/Zomato_delivery_time_analyser'\n",
        "data_path = 'Zomato_Data.csv'\n",
        "commit_hash = '2c33766'\n",
        "\n",
        "# Open the data stream using DVC\n",
        "with dvc.api.open(\n",
        "    path=data_path,\n",
        "    repo=repo_url,\n",
        "    rev=commit_hash\n",
        ") as data_stream:\n",
        "    df = pd.read_csv(data_stream)\n",
        "\n",
        "print(\"Dataset loaded successfully!\")\n",
        "print(\"Shape of the dataset:\", df.shape)\n",
        "df.head()\n",
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKlU0Wz5io4H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b1f6ed6",
        "outputId": "133a4749-ea54-486e-bc99-227ead0ce5bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data split successfully!\n",
            "Shape of X_train: (36075, 18)\n",
            "Shape of X_test: (9019, 18)\n",
            "Shape of y_train: (36075,)\n",
            "Shape of y_test: (9019,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = df.drop('Time_taken (min)', axis=1)\n",
        "y = df['Time_taken (min)']\n",
        "\n",
        "# Drop identifier columns\n",
        "X = X.drop(['ID', 'Delivery_person_ID'], axis=1)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Data split successfully!\")\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb2f5dce"
      },
      "source": [
        "### Baseline Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPcwMyxsBBF0"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import pandas as pd\n",
        "\n",
        "class DatetimeFeatureExtractor(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    A custom transformer to extract features from datetime columns.\n",
        "    \"\"\"\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        # Ensure the input is a DataFrame\n",
        "        df = X.copy()\n",
        "\n",
        "        # --- Feature 1: Food Preparation Time ---\n",
        "        # Convert time columns to datetime objects, coercing errors\n",
        "        time_ordered = pd.to_datetime(df['Time_Orderd'], errors='coerce')\n",
        "        time_picked = pd.to_datetime(df['Time_Order_picked'], errors='coerce')\n",
        "        # Calculate the difference in minutes\n",
        "        prep_time = (time_picked - time_ordered).dt.total_seconds() / 60\n",
        "\n",
        "        # --- Feature 2: Order Hour ---\n",
        "        order_hour = time_ordered.dt.hour\n",
        "\n",
        "        # --- Feature 3: Day of the Week ---\n",
        "        order_date = pd.to_datetime(df['Order_Date'], format='%d-%m-%Y', errors='coerce')\n",
        "        day_of_week = order_date.dt.dayofweek # Monday=0, Sunday=6\n",
        "\n",
        "        # Create a new DataFrame with the extracted features\n",
        "        extracted_features = pd.DataFrame({\n",
        "            'preparation_time_mins': prep_time,\n",
        "            'order_hour': order_hour,\n",
        "            'day_of_week': day_of_week\n",
        "        })\n",
        "\n",
        "        # Handle any NaNs that might have resulted from conversion errors\n",
        "        return extracted_features.fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bd61489",
        "outputId": "706073a1-82ee-45f1-bef3-b520d2fd36e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE with new features: 3.9938\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# --- Identify your column types ---\n",
        "numerical_cols = [\n",
        "    'Delivery_person_Age', 'Delivery_person_Ratings', 'Restaurant_latitude',\n",
        "    'Restaurant_longitude', 'Delivery_location_latitude', 'Delivery_location_longitude',\n",
        "    'Vehicle_condition', 'multiple_deliveries', 'distance (km)'\n",
        "]\n",
        "\n",
        "# Categorical columns\n",
        "categorical_cols = [\n",
        "    'Weather_conditions', 'Road_traffic_density', 'Type_of_order',\n",
        "    'Type_of_vehicle', 'Festival', 'City'\n",
        "]\n",
        "\n",
        "# Datetime columns that our custom transformer will handle\n",
        "datetime_cols = ['Order_Date', 'Time_Orderd', 'Time_Order_picked']\n",
        "\n",
        "# Create transformers for preprocessing\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        # 1. Apply our custom transformer to the datetime columns\n",
        "        ('datetime_features', DatetimeFeatureExtractor(), datetime_cols),\n",
        "\n",
        "        # 2. OneHotEncode the categorical columns\n",
        "        ('categorical_encoder', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
        "\n",
        "        # 3. Scale the numerical columns\n",
        "        ('numerical_scaler', StandardScaler(), numerical_cols)\n",
        "    ],\n",
        "    remainder='passthrough' # Keep any other columns (like lat/lon)\n",
        ")\n",
        "\n",
        "# --- Re-create your model pipeline ---\n",
        "# Let's use Random Forest as the example\n",
        "model_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', RandomForestRegressor(random_state=42)) # Or your tuned model\n",
        "])\n",
        "\n",
        "model_pipeline.fit(X_train, y_train)\n",
        "new_predictions = model_pipeline.predict(X_test)\n",
        "new_rmse = np.sqrt(mean_squared_error(y_test, new_predictions))\n",
        "print(f\"RMSE with new features: {new_rmse:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f359a0cc"
      },
      "outputs": [],
      "source": [
        "# Identify non-numeric columns\n",
        "non_numeric_cols = X_train.select_dtypes(exclude=np.number).columns\n",
        "print(\"Non-numeric columns:\", non_numeric_cols)\n",
        "\n",
        "# Display the first few rows of these columns to understand their content\n",
        "display(X_train[non_numeric_cols].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99f380a5"
      },
      "source": [
        "### Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6nTLB11aEw1g",
        "outputId": "3ac64fdf-beb5-4d02-f52f-96fe34f42abc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-3.4.0-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting mlflow-skinny==3.4.0 (from mlflow)\n",
            "  Downloading mlflow_skinny-3.4.0-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting mlflow-tracing==3.4.0 (from mlflow)\n",
            "  Downloading mlflow_tracing-3.4.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.1.2)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.16.5)\n",
            "Requirement already satisfied: cryptography<46,>=43.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (43.0.3)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fastmcp<3,>=2.0.0 (from mlflow)\n",
            "  Downloading fastmcp-2.12.3-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.2)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<22,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.16.2)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.43)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (8.2.1)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (3.1.1)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.4.0->mlflow)\n",
            "  Downloading databricks_sdk-0.67.0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (0.116.2)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (3.1.45)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (1.37.0)\n",
            "Collecting opentelemetry-proto<3,>=1.9.0 (from mlflow-skinny==3.4.0->mlflow)\n",
            "  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (1.37.0)\n",
            "Requirement already satisfied: packaging<26 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (25.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (2.11.9)\n",
            "Requirement already satisfied: python-dotenv<2,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (1.1.1)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (2.32.4)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (4.15.0)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow) (0.35.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<46,>=43.0.0->mlflow) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\n",
            "Requirement already satisfied: authlib>=1.5.2 in /usr/local/lib/python3.12/dist-packages (from fastmcp<3,>=2.0.0->mlflow) (1.6.4)\n",
            "Collecting cyclopts>=3.0.0 (from fastmcp<3,>=2.0.0->mlflow)\n",
            "  Downloading cyclopts-3.24.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting exceptiongroup>=1.2.2 (from fastmcp<3,>=2.0.0->mlflow)\n",
            "  Downloading exceptiongroup-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from fastmcp<3,>=2.0.0->mlflow) (0.28.1)\n",
            "Requirement already satisfied: mcp<2.0.0,>=1.12.4 in /usr/local/lib/python3.12/dist-packages (from fastmcp<3,>=2.0.0->mlflow) (1.14.1)\n",
            "Collecting openapi-core>=0.19.5 (from fastmcp<3,>=2.0.0->mlflow)\n",
            "  Downloading openapi_core-0.19.5-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting openapi-pydantic>=0.5.1 (from fastmcp<3,>=2.0.0->mlflow)\n",
            "  Downloading openapi_pydantic-0.5.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pyperclip>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from fastmcp<3,>=2.0.0->mlflow) (1.10.0)\n",
            "Requirement already satisfied: rich>=13.9.4 in /usr/local/lib/python3.12/dist-packages (from fastmcp<3,>=2.0.0->mlflow) (13.9.4)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (3.2.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<46,>=43.0.0->mlflow) (2.23)\n",
            "Requirement already satisfied: attrs>=23.1.0 in /usr/local/lib/python3.12/dist-packages (from cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow) (25.3.0)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow) (0.17.0)\n",
            "Collecting rich-rst<2.0.0,>=1.3.1 (from cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow)\n",
            "  Downloading rich_rst-1.3.1-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.12/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow) (2.38.0)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.4.0->mlflow) (0.48.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.4.0->mlflow) (4.0.12)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow) (0.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.4.0->mlflow) (3.23.0)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow) (0.4.1)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow) (4.25.1)\n",
            "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow) (2.10.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow) (0.0.20)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow) (3.0.2)\n",
            "Collecting isodate (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow)\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting jsonschema-path<0.4.0,>=0.3.1 (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow)\n",
            "  Downloading jsonschema_path-0.3.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow) (10.8.0)\n",
            "Collecting openapi-schema-validator<0.7.0,>=0.6.0 (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow)\n",
            "  Downloading openapi_schema_validator-0.6.3-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting openapi-spec-validator<0.8.0,>=0.7.1 (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow)\n",
            "  Downloading openapi_spec_validator-0.7.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting parse (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow)\n",
            "  Downloading parse-1.20.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting werkzeug>=3.1.0 (from Flask<4->mlflow)\n",
            "  Downloading werkzeug-3.1.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.4.0->mlflow) (0.58b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.4.0->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.4.0->mlflow) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.4.0->mlflow) (0.4.1)\n",
            "Collecting email-validator>=2.0.0 (from pydantic[email]>=2.11.7->fastmcp<3,>=2.0.0->mlflow)\n",
            "  Downloading email_validator-2.3.0-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.4.0->mlflow) (3.4.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.9.4->fastmcp<3,>=2.0.0->mlflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.9.4->fastmcp<3,>=2.0.0->mlflow) (2.19.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow) (1.3.1)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->pydantic[email]>=2.11.7->fastmcp<3,>=2.0.0->mlflow)\n",
            "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.4.0->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow) (4.9.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow) (0.27.1)\n",
            "Collecting pathable<0.5.0,>=0.4.1 (from jsonschema-path<0.4.0,>=0.3.1->openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow)\n",
            "  Downloading pathable-0.4.4-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->fastmcp<3,>=2.0.0->mlflow) (0.1.2)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow) (0.1.4)\n",
            "Collecting lazy-object-proxy<2.0.0,>=1.7.1 (from openapi-spec-validator<0.8.0,>=0.7.1->openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow)\n",
            "  Downloading lazy_object_proxy-1.12.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: docutils in /usr/local/lib/python3.12/dist-packages (from rich-rst<2.0.0,>=1.3.1->cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow) (0.21.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow) (0.6.1)\n",
            "Downloading mlflow-3.4.0-py3-none-any.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-3.4.0-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_tracing-3.4.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastmcp-2.12.3-py3-none-any.whl (314 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.0/314.0 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cyclopts-3.24.0-py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.2/86.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.67.0-py3-none-any.whl (718 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.4/718.4 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading exceptiongroup-1.3.0-py3-none-any.whl (16 kB)\n",
            "Downloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading openapi_core-0.19.5-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.6/106.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openapi_pydantic-0.5.1-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.4/224.4 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading email_validator-2.3.0-py3-none-any.whl (35 kB)\n",
            "Downloading jsonschema_path-0.3.4-py3-none-any.whl (14 kB)\n",
            "Downloading openapi_schema_validator-0.6.3-py3-none-any.whl (8.8 kB)\n",
            "Downloading openapi_spec_validator-0.7.2-py3-none-any.whl (39 kB)\n",
            "Downloading rich_rst-1.3.1-py3-none-any.whl (11 kB)\n",
            "Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Downloading parse-1.20.2-py2.py3-none-any.whl (20 kB)\n",
            "Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lazy_object_proxy-1.12.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathable-0.4.4-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: parse, werkzeug, pathable, opentelemetry-proto, lazy-object-proxy, isodate, gunicorn, graphql-core, exceptiongroup, dnspython, jsonschema-path, graphql-relay, email-validator, docker, rich-rst, openapi-pydantic, graphene, databricks-sdk, openapi-schema-validator, cyclopts, openapi-spec-validator, mlflow-tracing, mlflow-skinny, openapi-core, fastmcp, mlflow\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.1.3\n",
            "    Uninstalling Werkzeug-3.1.3:\n",
            "      Successfully uninstalled Werkzeug-3.1.3\n",
            "Successfully installed cyclopts-3.24.0 databricks-sdk-0.67.0 dnspython-2.8.0 docker-7.1.0 email-validator-2.3.0 exceptiongroup-1.3.0 fastmcp-2.12.3 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 isodate-0.7.2 jsonschema-path-0.3.4 lazy-object-proxy-1.12.0 mlflow-3.4.0 mlflow-skinny-3.4.0 mlflow-tracing-3.4.0 openapi-core-0.19.5 openapi-pydantic-0.5.1 openapi-schema-validator-0.6.3 openapi-spec-validator-0.7.2 opentelemetry-proto-1.37.0 parse-1.20.2 pathable-0.4.4 rich-rst-1.3.1 werkzeug-3.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7efdfa5",
        "outputId": "7f56f04b-3b74-4e5b-8ec7-3f0ab19be8bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting GridSearchCV with new features...\n",
            "\n",
            "--- RESULTS WITH NEW FEATURES ---\n",
            "Best parameters found: {'regressor__max_depth': 20, 'regressor__min_samples_split': 10, 'regressor__n_estimators': 300}\n",
            "New Tuned Random Forest RMSE on test set: 3.9503\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import mlflow\n",
        "\n",
        "# 1. Use your new, powerful pipeline as the estimator\n",
        "pipeline_with_new_features = model_pipeline\n",
        "\n",
        "# 2. Define the parameter grid\n",
        "param_grid = {\n",
        "    'regressor__n_estimators': [100, 200, 300],\n",
        "    'regressor__max_depth': [10, 20, None],\n",
        "    'regressor__min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# 3. Initialize and run GridSearchCV\n",
        "grid_search_new = GridSearchCV(pipeline_with_new_features, param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "\n",
        "print(\"Starting GridSearchCV with new features...\")\n",
        "grid_search_new.fit(X_train, y_train)\n",
        "\n",
        "# --- Evaluate the new best model ---\n",
        "best_model_new = grid_search_new.best_estimator_\n",
        "y_pred_new_tuned = best_model_new.predict(X_test)\n",
        "rmse_new_tuned = np.sqrt(mean_squared_error(y_test, y_pred_new_tuned))\n",
        "\n",
        "print(\"\\n--- RESULTS WITH NEW FEATURES ---\")\n",
        "print(\"Best parameters found:\", grid_search_new.best_params_)\n",
        "print(f\"New Tuned Random Forest RMSE on test set: {rmse_new_tuned:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "705348c6"
      },
      "source": [
        "# Aim: ML Modeling & Experiment Tracking\n",
        "\n",
        "**Objective:** Build ML pipeline, tune hyperparameters, track experiments with MLflow.\n",
        "\n",
        "The aim of this project is to build a machine learning pipeline to predict food delivery times on Zomato using features such as order times, weather conditions, traffic density, and geographic details of restaurants and delivery locations (latitude/longitude). Additionally, MLflow was integrated to track experiments, compare baseline and tuned models, and manage model artifacts.\n",
        "\n",
        "## Detailed Steps\n",
        "\n",
        "### Dataset Preparation\n",
        "\n",
        "Records of Zomato deliveries with attributes including:\n",
        "*   Time-based features: Order time, day of week.\n",
        "*   Weather conditions: Sunny, Rainy, Foggy, etc.\n",
        "*   Traffic density: Low, Medium, High, Jammed.\n",
        "*   Restaurant & Delivery location: Latitude, Longitude.\n",
        "*   Target variable: Delivery duration (minutes).\n",
        "\n",
        "The dataset was split into an 80% training set and a 20% testing set using a random seed of 42 for reproducibility.\n",
        "\n",
        "### Baseline Model Training\n",
        "\n",
        "The following baseline models were trained:\n",
        "*   Linear Regression\n",
        "*   Random Forest Regressor (default params)\n",
        "*   Gradient Boosting Regressor (default params)\n",
        "\n",
        "**Evaluation Metric:**\n",
        "RMSE (Root Mean Squared Error) was used for prediction accuracy.\n",
        "\n",
        "**Baseline Results (Test Set):**\n",
        "Based on the notebook execution, the baseline RMSE values were:\n",
        "*   Linear Regression: 5.9691\n",
        "*   Decision Tree: 5.3905\n",
        "*   Random Forest: 4.0047\n",
        "*   Gradient Boosting: 4.4806\n",
        "\n",
        "### Hyperparameter Tuning\n",
        "\n",
        "Hyperparameter tuning was applied to the Random Forest, Decision Tree, and Gradient Boosting models using `GridSearchCV`.\n",
        "\n",
        "**Random Forest (Tuned):**\n",
        "*   Best parameters found: `{'regressor__max_depth': 20, 'regressor__min_samples_split': 10, 'regressor__n_estimators': 300}`\n",
        "*   Tuned Test RMSE: 3.9503\n",
        "\n",
        "**Decision Tree (Tuned):**\n",
        "*   Best parameters found: `{'regressor__max_depth': 10, 'regressor__min_samples_leaf': 4, 'regressor__min_samples_split': 10}`\n",
        "*   Tuned Test RMSE: 4.2407\n",
        "\n",
        "**Gradient Boosting (Tuned):**\n",
        "*   Best parameters found: `{'regressor__learning_rate': 0.1, 'regressor__max_depth': 7, 'regressor__n_estimators': 100}`\n",
        "*   Tuned Test RMSE: 3.8871\n",
        "\n",
        "### Tuned Model Performance Comparison:\n",
        "\n",
        "Based on the notebook execution, the RMSE scores for all models are:\n",
        "*   Baseline Linear Regression: 5.9691\n",
        "*   Baseline Decision Tree: 5.3905\n",
        "*   Baseline Random Forest: 4.0047\n",
        "*   Baseline Gradient Boosting: 4.4806\n",
        "*   Tuned Random Forest: 3.9503\n",
        "*   Tuned Decision Tree: 4.2407\n",
        "*   Tuned Gradient Boosting: 3.8871\n",
        "\n",
        "The lowest RMSE was achieved by the Tuned Gradient Boosting model (3.8871). Hyperparameter tuning improved the performance of Random Forest, Decision Tree, and Gradient Boosting models compared to their baseline versions.\n",
        "\n",
        "### Experiment Tracking with MLflow\n",
        "\n",
        "MLflow was used to track the experiments, logging the parameters and metrics for both the baseline and tuned models.\n",
        "\n",
        "### Model Selection & Saving\n",
        "\n",
        "The Tuned Gradient Boosting model, having the lowest RMSE, was identified as the best-performing model. The notebook includes code to save this model using `joblib`.\n",
        "\n",
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   Hyperparameter tuning for the Decision Tree model using `GridSearchCV` identified the best parameters as `{'regressor__max_depth': 10, 'regressor__min_samples_leaf': 4, 'regressor__min_samples_split': 10}`, resulting in a best cross-validation RMSE of approximately 4.246.\n",
        "*   Hyperparameter tuning for the Gradient Boosting model using `GridSearchCV` identified the best parameters as `{'regressor__learning_rate': 0.1, 'regressor__max_depth': 7, 'regressor__n_estimators': 100}`, resulting in a best cross-validation RMSE of approximately 3.909.\n",
        "*   Evaluating the tuned models on the test set showed a tuned Decision Tree RMSE of 4.2407 and a tuned Gradient Boosting RMSE of 3.8871.\n",
        "*   The tuned Gradient Boosting model achieved the lowest RMSE (3.8871) among all evaluated models (baseline Linear Regression, Decision Tree, Random Forest, Gradient Boosting, and tuned versions).\n",
        "*   Hyperparameter tuning improved the performance (reduced RMSE) of the Random Forest, Decision Tree, and Gradient Boosting models compared to their baseline counterparts.\n",
        "*   The hyperparameters and RMSE metrics (cross-validation and test set) for the tuned Decision Tree and Gradient Boosting models were successfully logged to MLflow in a new run named \"Tuned Models Comparison\".\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The tuned Gradient Boosting model is the best-performing model based on the RMSE metric and should be considered for deployment.\n",
        "*   Further hyperparameter tuning with a wider grid or more advanced techniques (e.g., RandomizedSearchCV, Bayesian Optimization) could potentially yield even better performance.\n",
        "*   Consider exploring additional feature engineering based on the datetime features (e.g., rush hour indicators, time of day categories) which were used in one of the successful model runs.\n",
        "*   Investigate potential outliers or data quality issues that might be affecting model performance.\n",
        "*   Deploy the best-performing model for real-time delivery time predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cc80014"
      },
      "source": [
        "## Why RMSE Decreased After Hyperparameter Tuning\n",
        "\n",
        "Hyperparameter tuning improved the RMSE of the models (Random Forest, Decision Tree, and Gradient Boosting) because it allowed us to find more optimal configurations for the models' internal settings for this specific dataset.\n",
        "\n",
        "Think of hyperparameters as controls that influence how the model learns. By using `GridSearchCV`, we systematically tested different combinations of these controls (like the number of trees, depth of trees, learning rate, etc.). This process helps in several ways:\n",
        "\n",
        "*   **Better Fit to Data:** Tuning allows the model to better capture the complex relationships and patterns within your training data.\n",
        "*   **Improved Generalization:** By finding the right balance, tuning helps prevent the model from simply memorizing the training data (overfitting). A well-tuned model generalizes better to new, unseen data (like your test set).\n",
        "*   **Reduced Errors:** When the model learns the patterns more accurately and generalizes well, its predictions on the test set are closer to the actual values. RMSE measures the average prediction error, so more accurate predictions lead to a lower RMSE.\n",
        "\n",
        "In essence, hyperparameter tuning helps the model become more \"suited\" to the specific characteristics of the Zomato delivery time data, resulting in more accurate predictions and a lower RMSE compared to using default or less optimal settings."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dvc[gdrive] -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WQO9CibUOqMH",
        "outputId": "ccfa6473-86cc-46c2-a604-7c90fd43b5fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.8/438.8 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.9/73.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m466.2/466.2 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.9/374.9 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m753.1/753.1 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "Ci6c1qqLOwtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use your Personal Access Token (PAT) if your repo is private\n",
        "!git clone https://github.com/AshwinVK23/Zomato_delivery_time_analyser.git\n",
        "\n",
        "%cd Zomato_delivery_time_analyser"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfbOejQXO5Ay",
        "outputId": "3a66ee96-83ab-419c-b33c-c753650abc9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Zomato_delivery_time_analyser'...\n",
            "remote: Enumerating objects: 75, done.\u001b[K\n",
            "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 75 (delta 25), reused 54 (delta 13), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (75/75), 5.06 MiB | 7.06 MiB/s, done.\n",
            "Resolving deltas: 100% (25/25), done.\n",
            "/content/Zomato_delivery_time_analyser/Zomato_delivery_time_analyser\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!dvc pull models/delivery_model.pkl.dvc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ff1oz5YPNEU",
        "outputId": "63613e09-13ff-4992-92d9-3e03e1301e25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r!\r \r\r\r!\rCollecting          |0.00 [00:00,    ?entry/s]\rCollecting          |0.00 [00:00,    ?entry/s]\n",
            "\r!\rFetching/usr/local/lib/python3.12/dist-packages/oauth2client/_helpers.py:255: UserWarning: Cannot access /root/.cache/pydrive2fs/178551701615-9f8di2ohoe1ucketr0gjr6h062ronudj.apps.googleusercontent.com/default.json: No such file or directory\n",
            "  warnings.warn(_MISSING_FILE_MESSAGE.format(filename))\n",
            "Your browser has been opened to visit:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?client_id=178551701615-9f8di2ohoe1ucketr0gjr6h062ronudj.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8090%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.appdata&access_type=offline&response_type=code&approval_prompt=force\n",
            "\n",
            "4/0AVGzR1ARxjazPulXPtIhct5_1f7Uba5NWnp8NGLOY41fWTSBoQx3rixhcKxcaC4w0MOSlQ\n",
            "Fetching\n",
            "\u001b[31mERROR\u001b[39m: interrupted by the user\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXobmw2QSy4N",
        "outputId": "90ae80be-d339-463d-f147-c7086cadccca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "CHEp7MAaQRyw",
        "outputId": "7de4b8fa-a21d-45cd-bd9b-304e91f5afa2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'grid_search_new' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1169336757.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# This is your final, best-performing pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfinal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Save the model to a file named 'delivery_model.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'grid_search_new' is not defined"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# This is your final, best-performing pipeline\n",
        "final_model = grid_search_new.best_estimator_\n",
        "\n",
        "# Save the model to a file named 'delivery_model.pkl'\n",
        "joblib.dump(final_model, 'delivery_model.pkl')\n",
        "\n",
        "print(\"\\nFinal tuned model has been saved to 'delivery_model.pkl'\")\n",
        "\n",
        "# --- How to load it back in a new script ---\n",
        "# loaded_model = joblib.load('delivery_model.pkl')\n",
        "# predictions = loaded_model.predict(some_new_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4399b96e"
      },
      "source": [
        "### Experiment Tracking with MLflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# You still need to include the custom class definition for joblib to work\n",
        "class DatetimeFeatureExtractor(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None): return self\n",
        "    def transform(self, X, y=None):\n",
        "        df = X.copy()\n",
        "        time_ordered = pd.to_datetime(df['Time_Orderd'], errors='coerce')\n",
        "        time_picked = pd.to_datetime(df['Time_Order_picked'], errors='coerce')\n",
        "        prep_time = (time_picked - time_ordered).dt.total_seconds() / 60\n",
        "        order_hour = time_ordered.dt.hour\n",
        "        order_date = pd.to_datetime(df['Order_Date'], format='%d-%m-%Y', errors='coerce')\n",
        "        day_of_week = order_date.dt.dayofweek\n",
        "        extracted_features = pd.DataFrame({\n",
        "            'preparation_time_mins': prep_time, 'order_hour': order_hour, 'day_of_week': day_of_week\n",
        "        })\n",
        "        return extracted_features.fillna(0)\n",
        "\n",
        "# Define the path to your model file in Google Drive\n",
        "# Note: This assumes the file is in your main \"My Drive\" folder\n",
        "model_path = '/content/drive/My Drive/delivery_model.pkl'\n",
        "\n",
        "# Load the model\n",
        "model = joblib.load(model_path)\n",
        "\n",
        "print(\"✅ Model loaded successfully directly from Google Drive!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZhxo5e0TPU0",
        "outputId": "e3bee7b3-a4f7-433f-b625-4111fbc1f5f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded successfully directly from Google Drive!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# You must include the custom class definition so joblib can load your model\n",
        "class DatetimeFeatureExtractor(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None): return self\n",
        "    def transform(self, X, y=None):\n",
        "        df = X.copy()\n",
        "        time_ordered = pd.to_datetime(df['Time_Orderd'], errors='coerce')\n",
        "        time_picked = pd.to_datetime(df['Time_Order_picked'], errors='coerce')\n",
        "        prep_time = (time_picked - time_ordered).dt.total_seconds() / 60\n",
        "        order_hour = time_ordered.dt.hour\n",
        "        order_date = pd.to_datetime(df['Order_Date'], format='%d-%m-%Y', errors='coerce')\n",
        "        day_of_week = order_date.dt.dayofweek\n",
        "        extracted_features = pd.DataFrame({\n",
        "            'preparation_time_mins': prep_time, 'order_hour': order_hour, 'day_of_week': day_of_week\n",
        "        })\n",
        "        return extracted_features.fillna(0)\n",
        "\n",
        "# 1. Manually define the results from your Colab run\n",
        "best_params = {\n",
        "    'regressor__max_depth': 20,\n",
        "    'regressor__min_samples_split': 10,\n",
        "    'regressor__n_estimators': 300\n",
        "}\n",
        "test_rmse = 3.9503 # The score you found previously\n",
        "\n",
        "# 2. Load the model you downloaded from Colab\n",
        "model_to_log = model\n",
        "\n",
        "# 3. Set up and run MLflow logging\n",
        "mlflow.set_experiment(\"Zomato Delivery Time Prediction\")\n",
        "\n",
        "with mlflow.start_run(run_name=\"Tuned RF (from Colab)\"):\n",
        "    print(\"Logging parameters...\")\n",
        "    mlflow.log_params(best_params)\n",
        "\n",
        "    print(\"Logging metrics...\")\n",
        "    mlflow.log_metric(\"Test_RMSE\", test_rmse)\n",
        "\n",
        "    print(\"Logging model artifact...\")\n",
        "    mlflow.sklearn.log_model(model_to_log, \"tuned_rf_from_colab\")\n",
        "\n",
        "print(\"\\nFinished logging experiment to your local ML\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKB_F1XyJkoB",
        "outputId": "c501c6bc-476c-4e41-baf6-4292df3352a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/09/25 19:15:30 INFO mlflow.tracking.fluent: Experiment with name 'Zomato Delivery Time Prediction' does not exist. Creating a new experiment.\n",
            "2025/09/25 19:15:30 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging parameters...\n",
            "Logging metrics...\n",
            "Logging model artifact...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/09/25 19:15:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Finished logging experiment to your local ML\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JI9Cq3akVumN",
        "outputId": "8521a960-bc1a-4dbe-adbe-b9919cfd6061"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Click this link to view your MLflow UI: NgrokTunnel: \"https://09c2931e4ed5.ngrok-free.app\" -> \"http://localhost:5000\"\n"
          ]
        }
      ],
      "source": [
        "# Install pyngrok\n",
        "!pip install pyngrok -q\n",
        "\n",
        "# --- ADD YOUR AUTHTOKEN HERE ---\n",
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"2o991TRHcoXKCNwuPFeJfVaEJUA_2hyxaxgnv3ekSVG9vDtoZ\") # <--- Paste your token here\n",
        "\n",
        "# Run the MLflow UI in the background\n",
        "get_ipython().system_raw(\"mlflow ui --port 5000 &\")\n",
        "\n",
        "# Create the tunnel to the MLflow UI\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"Click this link to view your MLflow UI: {public_url}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd3f0e8d"
      },
      "source": [
        "### Model Selection & Saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dcceb20",
        "outputId": "df2e13f0-0797-44f9-8b82-6da6f5e66930"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best model saved to: saved_models/tuned_random_forest_model.pkl\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "import os\n",
        "\n",
        "# Select the best-performing model (tuned Random Forest)\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Define the directory to save the model\n",
        "model_dir = \"saved_models\"\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "# Define the model filename\n",
        "model_filename = os.path.join(model_dir, \"tuned_random_forest_model.pkl\")\n",
        "\n",
        "# Save the model using joblib\n",
        "joblib.dump(best_model, model_filename)\n",
        "\n",
        "print(f\"Best model saved to: {model_filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e27b36c7"
      },
      "source": [
        "# Task\n",
        "Perform hyperparameter tuning for the Decision Tree and Gradient Boosting models using GridSearchCV with RMSE as the scoring metric. Evaluate the tuned models on the test set and compare their performance with the previously evaluated models. Log the results of the tuned models to MLflow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41893dcb"
      },
      "source": [
        "## Hyperparameter tuning for decision tree\n",
        "\n",
        "### Subtask:\n",
        "Define a parameter grid for the `DecisionTreeRegressor`, set up a `GridSearchCV` with the preprocessing pipeline, fit it to the training data, and print the best parameters and cross-validation RMSE.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc843de8"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the parameter grid for Decision Tree, set up the pipeline and GridSearchCV, fit it to the training data, and print the best parameters and cross-validation RMSE as requested in the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91f72145",
        "outputId": "aa65b076-db13-4534-f3e1-b3b0b611e6da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting GridSearchCV for Decision Tree...\n",
            "GridSearchCV for Decision Tree complete.\n",
            "Best parameters found for Decision Tree: {'regressor__max_depth': 10, 'regressor__min_samples_leaf': 4, 'regressor__min_samples_split': 10}\n",
            "Best cross-validation RMSE for Decision Tree: 4.2458788204076425\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Define the parameter grid for DecisionTreeRegressor\n",
        "dt_param_grid = {\n",
        "    'regressor__max_depth': [10, 20, 30, None],\n",
        "    'regressor__min_samples_split': [2, 5, 10],\n",
        "    'regressor__min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Identify categorical and datetime columns (same as before)\n",
        "categorical_cols = X_train.select_dtypes(include='object').columns.tolist()\n",
        "datetime_cols = ['Order_Date', 'Time_Orderd', 'Time_Order_picked']\n",
        "categorical_cols = [col for col in categorical_cols if col not in datetime_cols]\n",
        "\n",
        "# Create the preprocessor (same as before)\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('drop_datetime', 'drop', datetime_cols),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "\n",
        "# Create a pipeline with the preprocessor and the Decision Tree Regressor\n",
        "dt_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                              ('regressor', DecisionTreeRegressor(random_state=42))])\n",
        "\n",
        "# Initialize GridSearchCV for Decision Tree\n",
        "dt_grid_search = GridSearchCV(dt_pipeline, dt_param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "\n",
        "# Fit GridSearchCV to the training data\n",
        "print(\"Starting GridSearchCV for Decision Tree...\")\n",
        "dt_grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"GridSearchCV for Decision Tree complete.\")\n",
        "print(\"Best parameters found for Decision Tree:\", dt_grid_search.best_params_)\n",
        "print(\"Best cross-validation RMSE for Decision Tree:\", np.sqrt(-dt_grid_search.best_score_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54872118"
      },
      "source": [
        "## Hyperparameter tuning for gradient boosting\n",
        "\n",
        "### Subtask:\n",
        "Define a parameter grid for the `GradientBoostingRegressor`, set up a `GridSearchCV` with the preprocessing pipeline, fit it to the training data, and print the best parameters and cross-validation RMSE.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dcd3b86"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the parameter grid for Gradient Boosting, set up the pipeline and GridSearchCV, fit it to the training data, and print the best parameters and cross-validation RMSE as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e195655",
        "outputId": "edb36dfc-546f-4f6b-ad64-bfca18f888ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting GridSearchCV for Gradient Boosting...\n",
            "GridSearchCV for Gradient Boosting complete.\n",
            "Best parameters found for Gradient Boosting: {'regressor__learning_rate': 0.1, 'regressor__max_depth': 7, 'regressor__n_estimators': 100}\n",
            "Best cross-validation RMSE for Gradient Boosting: 3.9092237076570644\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Define the parameter grid for GradientBoostingRegressor\n",
        "gb_param_grid = {\n",
        "    'regressor__n_estimators': [100, 200, 300],\n",
        "    'regressor__learning_rate': [0.01, 0.1, 0.2],\n",
        "    'regressor__max_depth': [3, 5, 7]\n",
        "}\n",
        "\n",
        "# Identify categorical and datetime columns (same as before)\n",
        "categorical_cols = X_train.select_dtypes(include='object').columns.tolist()\n",
        "datetime_cols = ['Order_Date', 'Time_Orderd', 'Time_Order_picked']\n",
        "categorical_cols = [col for col in categorical_cols if col not in datetime_cols]\n",
        "\n",
        "# Create the preprocessor (same as before)\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('drop_datetime', 'drop', datetime_cols),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Create a pipeline with the preprocessor and the Gradient Boosting Regressor\n",
        "gb_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                              ('regressor', GradientBoostingRegressor(random_state=42))])\n",
        "\n",
        "# Initialize GridSearchCV for Gradient Boosting\n",
        "gb_grid_search = GridSearchCV(gb_pipeline, gb_param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "\n",
        "# Fit GridSearchCV to the training data\n",
        "print(\"Starting GridSearchCV for Gradient Boosting...\")\n",
        "gb_grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"GridSearchCV for Gradient Boosting complete.\")\n",
        "print(\"Best parameters found for Gradient Boosting:\", gb_grid_search.best_params_)\n",
        "print(\"Best cross-validation RMSE for Gradient Boosting:\", np.sqrt(-gb_grid_search.best_score_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63ab6cc5"
      },
      "source": [
        "## Evaluate tuned models on test set\n",
        "\n",
        "### Subtask:\n",
        "Use the best estimators from the `GridSearchCV` for Decision Tree and Gradient Boosting to make predictions on the test set (`X_test`) and calculate their RMSE.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ad079e6"
      },
      "source": [
        "**Reasoning**:\n",
        "Use the best estimators from the GridSearch for Decision Tree and Gradient Boosting to predict on the test set and calculate their RMSE.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aa45fe9",
        "outputId": "3c086bb7-f3ce-4109-c9ee-d74180a54d8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tuned Decision Tree RMSE on test set: 4.2407\n",
            "Tuned Gradient Boosting RMSE on test set: 3.8871\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Get the best estimator for the Decision Tree model\n",
        "best_dt_model = dt_grid_search.best_estimator_\n",
        "\n",
        "# Use the best Decision Tree estimator to predict on the test set\n",
        "y_pred_dt_tuned = best_dt_model.predict(X_test)\n",
        "\n",
        "# Calculate the RMSE for the tuned Decision Tree model\n",
        "rmse_dt_tuned = np.sqrt(mean_squared_error(y_test, y_pred_dt_tuned))\n",
        "\n",
        "# Get the best estimator for the Gradient Boosting model\n",
        "best_gb_model = gb_grid_search.best_estimator_\n",
        "\n",
        "# Use the best Gradient Boosting estimator to predict on the test set\n",
        "y_pred_gb_tuned = best_gb_model.predict(X_test)\n",
        "\n",
        "# Calculate the RMSE for the tuned Gradient Boosting model\n",
        "rmse_gb_tuned = np.sqrt(mean_squared_error(y_test, y_pred_gb_tuned))\n",
        "\n",
        "# Print the calculated RMSE for both tuned models\n",
        "print(f\"Tuned Decision Tree RMSE on test set: {rmse_dt_tuned:.4f}\")\n",
        "print(f\"Tuned Gradient Boosting RMSE on test set: {rmse_gb_tuned:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f819053"
      },
      "source": [
        "## Compare tuned model performance\n",
        "\n",
        "### Subtask:\n",
        "Present a comparison of the RMSE scores for all models: the baseline models, the tuned Random Forest, the tuned Decision Tree, and the tuned Gradient Boosting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0572968a"
      },
      "source": [
        "**Reasoning**:\n",
        "Create a dictionary to store all the RMSE values and print them in a formatted way to compare the model performances.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5d297ae",
        "outputId": "31218a87-429a-4736-b536-d27d9d5bb399"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Performance Comparison (RMSE):\n",
            "- Baseline Linear Regression: 5.9691\n",
            "- Baseline Decision Tree: 5.3905\n",
            "- Baseline Random Forest: 4.0047\n",
            "- Baseline Gradient Boosting: 4.4806\n",
            "- Tuned Random Forest: 3.9478\n",
            "- Tuned Decision Tree: 4.2407\n",
            "- Tuned Gradient Boosting: 3.8871\n",
            "\n",
            "Interpretation:\n",
            "The lowest RMSE was achieved by the Tuned Gradient Boosting model: 3.8871\n",
            "Hyperparameter tuning improved the performance of Random Forest, Decision Tree, and Gradient Boosting models compared to their baseline versions.\n"
          ]
        }
      ],
      "source": [
        "# Create a dictionary to store all RMSE values\n",
        "all_model_rmse = {\n",
        "    'Baseline Linear Regression': results['Linear Regression'],\n",
        "    'Baseline Decision Tree': results['Decision Tree'],\n",
        "    'Baseline Random Forest': results['Random Forest'],\n",
        "    'Baseline Gradient Boosting': results['Gradient Boosting'],\n",
        "    'Tuned Random Forest': rmse_tuned,\n",
        "    'Tuned Decision Tree': rmse_dt_tuned,\n",
        "    'Tuned Gradient Boosting': rmse_gb_tuned\n",
        "}\n",
        "\n",
        "# Print the RMSE values for all models\n",
        "print(\"Model Performance Comparison (RMSE):\")\n",
        "for name, rmse in all_model_rmse.items():\n",
        "    print(f\"- {name}: {rmse:.4f}\")\n",
        "\n",
        "# Interpret the results\n",
        "print(\"\\nInterpretation:\")\n",
        "print(f\"The lowest RMSE was achieved by the Tuned Gradient Boosting model: {all_model_rmse['Tuned Gradient Boosting']:.4f}\")\n",
        "print(\"Hyperparameter tuning improved the performance of Random Forest, Decision Tree, and Gradient Boosting models compared to their baseline versions.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a603661e"
      },
      "source": [
        "## Log tuned model results to mlflow\n",
        "\n",
        "### Subtask:\n",
        "Update the MLflow tracking code to include the results and parameters of the tuned Decision Tree and Gradient Boosting models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd8b8e47"
      },
      "source": [
        "**Reasoning**:\n",
        "Log the results and parameters of the tuned Decision Tree and Gradient Boosting models to MLflow.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34d5007a",
        "outputId": "43995d62-708b-4f49-d220-dd76ec382fc2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/17 10:16:51 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/09/17 10:16:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2025/09/17 10:16:55 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/09/17 10:17:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logged tuned Decision Tree and Gradient Boosting model results to MLflow.\n"
          ]
        }
      ],
      "source": [
        "# Start a new MLflow run for tuned models comparison\n",
        "with mlflow.start_run(run_name=\"Tuned Models Comparison\"):\n",
        "    # Log hyperparameters for Tuned Decision Tree\n",
        "    for param, value in dt_grid_search.best_params_.items():\n",
        "        mlflow.log_param(f\"Decision Tree - {param}\", value)\n",
        "\n",
        "    # Log best cross-validation RMSE for Tuned Decision Tree\n",
        "    mlflow.log_metric(\"Decision Tree - Best CV RMSE\", np.sqrt(-dt_grid_search.best_score_))\n",
        "\n",
        "    # Log test set RMSE for Tuned Decision Tree\n",
        "    mlflow.log_metric(\"Decision Tree - Tuned Test RMSE\", rmse_dt_tuned)\n",
        "\n",
        "    # Optionally log the tuned Decision Tree model\n",
        "    mlflow.sklearn.log_model(best_dt_model, \"tuned_decision_tree_model\")\n",
        "\n",
        "    # Log hyperparameters for Tuned Gradient Boosting\n",
        "    for param, value in gb_grid_search.best_params_.items():\n",
        "        mlflow.log_param(f\"Gradient Boosting - {param}\", value)\n",
        "\n",
        "    # Log best cross-validation RMSE for Tuned Gradient Boosting\n",
        "    mlflow.log_metric(\"Gradient Boosting - Best CV RMSE\", np.sqrt(-gb_grid_search.best_score_))\n",
        "\n",
        "    # Log test set RMSE for Tuned Gradient Boosting\n",
        "    mlflow.log_metric(\"Gradient Boosting - Tuned Test RMSE\", rmse_gb_tuned)\n",
        "\n",
        "    # Optionally log the tuned Gradient Boosting model\n",
        "    mlflow.sklearn.log_model(best_gb_model, \"tuned_gradient_boosting_model\")\n",
        "\n",
        "print(\"Logged tuned Decision Tree and Gradient Boosting model results to MLflow.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36bba6ad"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   Hyperparameter tuning for the Decision Tree model using `GridSearchCV` identified the best parameters as `{'regressor__max_depth': 10, 'regressor__min_samples_leaf': 4, 'regressor__min_samples_split': 10}`, resulting in a best cross-validation RMSE of approximately 4.246.\n",
        "*   Hyperparameter tuning for the Gradient Boosting model using `GridSearchCV` identified the best parameters as `{'regressor__learning_rate': 0.1, 'regressor__max_depth': 7, 'regressor__n_estimators': 100}`, resulting in a best cross-validation RMSE of approximately 3.909.\n",
        "*   Evaluating the tuned models on the test set showed a tuned Decision Tree RMSE of 4.2407 and a tuned Gradient Boosting RMSE of 3.8871.\n",
        "*   The tuned Gradient Boosting model achieved the lowest RMSE (3.8871) among all evaluated models (baseline Linear Regression, Decision Tree, Random Forest, Gradient Boosting, and tuned versions).\n",
        "*   Hyperparameter tuning improved the performance (reduced RMSE) of the Random Forest, Decision Tree, and Gradient Boosting models compared to their baseline counterparts.\n",
        "*   The hyperparameters and RMSE metrics (cross-validation and test set) for the tuned Decision Tree and Gradient Boosting models were successfully logged to MLflow in a new run named \"Tuned Models Comparison\".\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The tuned Gradient Boosting model is the best-performing model based on the RMSE metric and should be considered for deployment.\n",
        "*   Further hyperparameter tuning with a wider grid or more advanced techniques (e.g., RandomizedSearchCV, Bayesian Optimization) could potentially yield even better performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnrItTgv5frp",
        "outputId": "fbf3ffa0-aa9a-4f26-d93d-8bd7f3c0a13d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VTX1uToU6YPE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}